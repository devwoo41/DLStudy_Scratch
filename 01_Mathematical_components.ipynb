{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080ae67d",
   "metadata": {},
   "source": [
    "## 신경망의 수학적 구성요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de34236",
   "metadata": {},
   "source": [
    "### 1. 신경망 훑어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c6f28",
   "metadata": {},
   "source": [
    "#### 케라스 이용해서 MNIST 데이터셋을 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc3f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b585f",
   "metadata": {},
   "source": [
    "#### 훈련 데이터 / 테스트 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11fadef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28), length: 60000\n",
      "Test images shape: (10000, 28, 28), length: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train images shape: {train_images.shape}, length: {len(train_images)}')\n",
    "print(f'Test images shape: {test_images.shape}, length: {len(test_images)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7069eb",
   "metadata": {},
   "source": [
    "#### 신경망 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd9d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e43d3e",
   "metadata": {},
   "source": [
    "#### 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf0b0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791592c",
   "metadata": {},
   "source": [
    "#### 이미지 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3e98d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32') / 255 # 255로 나누어 0~1 사이의 값으로 정규화\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255 # 255로 나누어 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41599f09",
   "metadata": {},
   "source": [
    "#### 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d022fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2547 - accuracy: 0.9261\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1046 - accuracy: 0.9690\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0688 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0491 - accuracy: 0.9854\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0379 - accuracy: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x74275f646d00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c6032",
   "metadata": {},
   "source": [
    "#### 모델을 사용하여 예측 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14eba58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.6812760e-09, 6.0640756e-11, 3.9211287e-07, 2.7299544e-05,\n",
       "       4.2678209e-12, 1.3394897e-07, 4.5295911e-12, 9.9997199e-01,\n",
       "       3.2470229e-08, 2.6499220e-07], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff874cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()  # 예측한 숫자, 가장 높은 확률을 가진 인덱스 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6706934",
   "metadata": {},
   "source": [
    "#### 예측값과 실제가 맞았는지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "613d068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답입니다!\n"
     ]
    }
   ],
   "source": [
    "if predictions[0].argmax() == test_labels[0]:\n",
    "    print(\"정답입니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3a164",
   "metadata": {},
   "source": [
    "#### 새로운 데이터에서 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea7009ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9783\n",
      "Test accuracy: 0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10dc38a",
   "metadata": {},
   "source": [
    "### 2. 신경망을 위한 데이터표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70e15e",
   "metadata": {},
   "source": [
    "#### 데이터셋 호출 및 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc2e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축의 개수: 3\n",
      "훈련 이미지의 형상: (60000, 28, 28)\n",
      "훈련 이미지의 데이터 타입: uint8\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(f'축의 개수: {train_images.ndim}')\n",
    "print(f'훈련 이미지의 형상: {train_images.shape}')\n",
    "print(f'훈련 이미지의 데이터 타입: {train_images.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479be0a6",
   "metadata": {},
   "source": [
    "#### 여섯 번째 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27328da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_images[5]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9461777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed76268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슬라이스된 이미지의 형상: (90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(f'슬라이스된 이미지의 형상: {my_slice.shape}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d71094",
   "metadata": {},
   "source": [
    "#### 배치 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c272c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치1의 형상: (128, 28, 28)\n",
      "배치2의 형상: (128, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "batch1 = train_images[0:128]\n",
    "batch2 = train_images[128:256]\n",
    "print(f'배치1의 형상: {batch1.shape}')\n",
    "print(f'배치2의 형상: {batch2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75396b",
   "metadata": {},
   "source": [
    "#### 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925b19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2  # 2D 텐서인지 확인, x는 랭크-2 넘파이 배열\n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x\n",
    "\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f014e5cd",
   "metadata": {},
   "source": [
    "#### 시간 비교 (numpy 연산 vs. 일반 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc199b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "넘파이 연산 걸린 시간 : 0.01 s\n",
      "나이브 연산 걸린 시간 : 0.74 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0)\n",
    "print(f'넘파이 연산 걸린 시간 : {time.time() - t0:.2f} s')\n",
    "\n",
    "t1 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(f'나이브 연산 걸린 시간 : {time.time() - t1:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa13e8a",
   "metadata": {},
   "source": [
    "#### 브로드캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86d2219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((32,10)) \n",
    "y = np.random.random((10,))\n",
    "\n",
    "y = np.expand_dims(y, axis=0)\n",
    "\n",
    "Y = np.concatenate([y]*32, axis=0)  # y를 32번 복제하여 배치 크기에 맞춤\n",
    "\n",
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ba49a",
   "metadata": {},
   "source": [
    "#### 텐서 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98ed600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z=0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x는 넘파이 행렬\n",
    "    assert len(y.shape) == 1 # y는 넘파이 벡터\n",
    "    assert x.shape[1] == y.shape[0] # x의 두 번째 차원이 y의 첫 번째 차원과 같아야 합니다\n",
    "    z = np.zeros(x.shape[0]) # 이 연산은 x의 행과 같은 크기의 0이 채워진 벡터를 만듭니다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i,j] * y[j]\n",
    "    return z\n",
    "\n",
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ea74a",
   "metadata": {},
   "source": [
    "#### 텐서플로의 그레이디언트 테이프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ebe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2*x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "\n",
    "x = tf.Variable(tf.zeros((2,2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((2,2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2,2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W = tape.gradient(y, [W,b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0a646",
   "metadata": {},
   "source": [
    "#### 텐서플로를 사용하여 밑바닥부터 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4441cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights\n",
    "        return weights\n",
    "\n",
    "import math    \n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels\n",
    "    \n",
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(learning_rate * g)\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))\n",
    "\n",
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f'에포크 {epoch_counter}')\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f'  배치 {batch_counter}, 손실값: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4de56cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0\n",
      "  배치 0, 손실값: 4.55\n",
      "  배치 100, 손실값: 2.24\n",
      "  배치 200, 손실값: 2.22\n",
      "  배치 300, 손실값: 2.07\n",
      "  배치 400, 손실값: 2.20\n",
      "에포크 1\n",
      "  배치 0, 손실값: 1.91\n",
      "  배치 100, 손실값: 1.88\n",
      "  배치 200, 손실값: 1.84\n",
      "  배치 300, 손실값: 1.69\n",
      "  배치 400, 손실값: 1.82\n",
      "에포크 2\n",
      "  배치 0, 손실값: 1.59\n",
      "  배치 100, 손실값: 1.59\n",
      "  배치 200, 손실값: 1.52\n",
      "  배치 300, 손실값: 1.41\n",
      "  배치 400, 손실값: 1.50\n",
      "에포크 3\n",
      "  배치 0, 손실값: 1.34\n",
      "  배치 100, 손실값: 1.35\n",
      "  배치 200, 손실값: 1.26\n",
      "  배치 300, 손실값: 1.20\n",
      "  배치 400, 손실값: 1.28\n",
      "에포크 4\n",
      "  배치 0, 손실값: 1.14\n",
      "  배치 100, 손실값: 1.17\n",
      "  배치 200, 손실값: 1.06\n",
      "  배치 300, 손실값: 1.04\n",
      "  배치 400, 손실값: 1.11\n",
      "에포크 5\n",
      "  배치 0, 손실값: 1.00\n",
      "  배치 100, 손실값: 1.03\n",
      "  배치 200, 손실값: 0.92\n",
      "  배치 300, 손실값: 0.92\n",
      "  배치 400, 손실값: 0.99\n",
      "에포크 6\n",
      "  배치 0, 손실값: 0.89\n",
      "  배치 100, 손실값: 0.92\n",
      "  배치 200, 손실값: 0.81\n",
      "  배치 300, 손실값: 0.83\n",
      "  배치 400, 손실값: 0.90\n",
      "에포크 7\n",
      "  배치 0, 손실값: 0.81\n",
      "  배치 100, 손실값: 0.84\n",
      "  배치 200, 손실값: 0.73\n",
      "  배치 300, 손실값: 0.76\n",
      "  배치 400, 손실값: 0.83\n",
      "에포크 8\n",
      "  배치 0, 손실값: 0.74\n",
      "  배치 100, 손실값: 0.77\n",
      "  배치 200, 손실값: 0.67\n",
      "  배치 300, 손실값: 0.71\n",
      "  배치 400, 손실값: 0.78\n",
      "에포크 9\n",
      "  배치 0, 손실값: 0.69\n",
      "  배치 100, 손실값: 0.71\n",
      "  배치 200, 손실값: 0.62\n",
      "  배치 300, 손실값: 0.66\n",
      "  배치 400, 손실값: 0.74\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size = 28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581698a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.82\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f'accuracy : {matches.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f02eb",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a78b3",
   "metadata": {},
   "source": [
    "##### 클래스와 레이블에 관한 노트\n",
    "\n",
    "- 머신 러닝에서 분류 문제의 범주(category)를 클래스(class)라고 한다. 데이터 포인트는 샘플(sample)이라고 한다. 특정 샘플의 클래스는 레이블(label)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0289e5b",
   "metadata": {},
   "source": [
    "#### 신경망의 핵심구조\n",
    "\n",
    "- 신경망의 핵심 구성 요소는 층이다. 층은 데이터를 위한 필터(filter)로 생각할 수 있다. 어떤 데이터가 들어가면 더 유용한 형태로 출력된다. 조금 더 구체적으로 층은 주어진 문제에 더 의미있는 표현을 입력된 데이터로부터 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907d9e6",
   "metadata": {},
   "source": [
    "#### 신경망의 훈련준비를 마치기 위한 컴파일 단계에서의 결정 사항\n",
    "\n",
    "- 옵티마이저(optimizer) : 성능을 향상시키기 위해 입력된 데이터를 기반으로 모델을 업데이트하는 메커니즘\n",
    "\n",
    "- 손실 함수(loss function) : 훈련 데이터에서 모델의 성능을 측정하는 방법으로 모델이 옳은 방향으로 학습될 수 있도록 도와준다.\n",
    "\n",
    "- 훈련과 테스트 과정을 모니터링할 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134025c",
   "metadata": {},
   "source": [
    "#### 기본 데이터 구조인 텐서\n",
    "\n",
    "- 텐서는 데이터를 위한 컨테이너이다. 일반적으로 수치형 데이터를 다루므로 숫자를 위한 컨테이너이다. *행렬*은 *랭크-2 텐서*이다. 텐서는 일반적으로 임의의 차원 개수를 가지는 행렬의 일반화된 모습이다. 텐서에서는 차원(dimension)을 종종 축(axis)라고 부른다.\n",
    "\n",
    "- 스칼라(랭크-0 텐서), 벡터(링크-1텐서), 행렬(랭크-2텐서), 랭크-3텐서와 더 높은 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09527abe",
   "metadata": {},
   "source": [
    "#### 텐서의 핵심 속성\n",
    "\n",
    "- 축의 개수(랭크) : 랭크-3텐서에는 3개의 축이 있고, 행렬(랭크-2 텐서)에는 2개의 축이 있다. 넘파이나 텐서플로 같은 파이썬 라이브러리에서는 ndim 속성에 저장되어 있다.\n",
    "\n",
    "- 크기 : 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플(tuple)이다.\n",
    "\n",
    "- 데이터 타입 : 텐서에 포함된 데이터의 타입으로, float16, float32, uint8 등등이 될 수 있다. 텐서플로에서는 string 텐서를 사용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68ac71",
   "metadata": {},
   "source": [
    "#### 텐서의 실제 사례\n",
    "\n",
    "- 벡터 데이터 : (samples, features)\n",
    "\n",
    "- 시계열 데이터 : (samples, timesteps, features)\n",
    "\n",
    "- 이미지 : (samples, height, width, channels) & (samples, channels, height, width)\n",
    "\n",
    "- 동영상 : (samples, frames, height, width, channels) & (samples, frames, channels, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1a59b",
   "metadata": {},
   "source": [
    "#### 브로드캐스팅\n",
    "\n",
    "- 큰 텐서의 ndim에 맞도록 작은 텐서에 (브로드캐스팅 축이라고 부르는) 축이 추가된다.\n",
    "\n",
    "- 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac52e3",
   "metadata": {},
   "source": [
    "#### 그레이디언트 기반 최적화\n",
    "\n",
    "- 훈련 샘플 x와 이에 상응하는 타깃 y_true의 배치를 추출합니다.\n",
    "\n",
    "- x를 사용하여 모델을 실행하고(정방향 패스(forward pass) 단계), 예측 y_pred를 구한다.\n",
    "\n",
    "- y_pred와 y_true의 차이를 측정하여 이 배치에 대한 모델의 손실을 계산한다.\n",
    "\n",
    "- 배치에 대한 손실이 조금 감소되도록 모델의 모든 가중치를 업데이트한다.\n",
    "\n",
    "=> 결국 훈련 데이터에서 모델의 손실, 즉 예측 y_pred와 타깃 y_true의 오차가 매우 작아질것이고, 이 모델은 입력에 정확한 타깃을 매핑하는 것을 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643db93",
   "metadata": {},
   "source": [
    "#### 도함수 연결 : 역전파 알고리즘\n",
    "\n",
    "- 연쇄 법칙 \n",
    "\n",
    "- 계산 그래프"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
